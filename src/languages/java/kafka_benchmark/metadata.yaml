# metadata.yaml for Kafka CPU Benchmark
name: kafka_cpu_benchmark
type: macrobenchmark
language: Java
domain:
  - messaging
  - streaming

setup:
  command: ./setup.sh

workloads:
  - name: kafka_producer_perf
    summary: Kafka message producer throughput benchmark
    action: publish high-volume message streams to Kafka
    description: >
      Launch a local Kafka broker and Zookeeper ensemble to establish a messaging cluster.
      Execute parallel producer threads using the `kafka-producer-perf-test` tool to flood a topic with compressed records.
      Measure the total time required to publish a fixed volume of messages, evaluating CPU efficiency in serialization, compression, and I/O handling.
    command: python3 run_benchmark.py
    parameters:
      num-records:
        full_name: number of records
        description: Total number of records to produce across all threads
        default: 1000000000
      record-size:
        full_name: record size
        description: Size of each record in bytes
        default: 1
      threads:
        full_name: number of producer threads
        description: Number of parallel producers
        default: 1
      iters:
        full_name: number of iterations
        description: Number of benchmark iterations
        default: 1
      warmup:
        full_name: enable warmup
        description: Run a warmup iteration before benchmarking
        default: true

characteristics:
  IO_effects: high
  single_machine: true
  network_effects: loopback_only
  cpu_bound: true
  memory_intensive: medium  

tags:
  - kafka
  - streaming
  - messaging

dependencies:
  python: ">=3.8"
  java: ">=11"
  kafka: "3.8.0"

# metadata.yaml for BERT CPU benchmark
name: bert_cpu
type: macrobenchmark
language: Python
domain:
  - natural_language_processing
  - transformer_models
  - deep_learning

setup:
  command: python3 setup.py

workloads:
  - name: bert_eval
    summary: BERT deep learning inference benchmark on CPU
    action: execute forward pass inference with BERT model
    description: >
      Load pre-generated input batches and initialize the BERT model in evaluation mode.
      Execute the forward pass on the CPU to process input sequences without gradient calculation.
      Measure the inference latency to assess the CPU's performance on Transformer-based NLP workloads.
    data:
      command: python3 generate_data.py
      parameters:
        batch_size:
          full_name: batch size
          description: Batch size for each batch
          default: 16
        seq_len:
          full_name: sequence length
          description: Sequence length for each input
          default: 1024
        num_batches:
          full_name: number of batches
          description: Number of batches
          default: 50
        output_dir:
          full_name: output directory
          description: Directory to save generated batches
          default: ./data
    command: python3 bert_eval.py
    parameters:
      data_dir:
        full_name: data directory
        description: Directory containing pre-generated input batches
        default: ./data
      threads:
        full_name: threads
        description: Number of CPU threads to use for training
        default: 1
      lr:
        full_name: learning rate
        description: Learning rate for optimizer
        default: 0.001
      compile:
        full_name: compile
        description: Use torch.compile
        default: false

characteristics:
  IO_effects: low
  single_machine: true
  network_effects: none
  cpu_bound: true
  memory_intensive: low

tags:
  - transformer
  - NLP
  - deep_learning
  - training

dependencies:
  python: ">=3.8"
  torch: ">=2.0"
  transformers: ">=4.30"

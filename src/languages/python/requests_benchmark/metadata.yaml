# metadata.yaml for Requests JSON Parsing Benchmark
name: requests_benchmark
type: microbenchmark      
language: Python
domain:                     
  - parsing
  - json
  - memory

setup:
  command: python3 setup.py

workloads:
  - name: requests-json
    summary: JSON parsing benchmark using Python requests library
    action: parse JSON data from local file responses
    description: >
      Initialize a requests session with a local file adapter to simulate HTTP responses from memory-cached files.
      Execute repeated GET requests to retrieve JSON payloads and parse them into Python dictionaries.
      Measure the CPU time required for data serialization and object creation to evaluate JSON processing performance.
    command: python3 -m scripts.run_benchmark
    parameters:
      threads:
        description: Number of parallel worker processes
        default: 1
      iters:
        description: Iterations per worker process
        default: 1000
      warmup:
        description: Warmup iterations per worker
        default: 3
      size:
        description: Dataset size, affects generated JSON file
        default: 262144
      force:
        description: Force regenerate dataset even if it exists
        default: false

characteristics:
  IO_effects: minimal         
  single_machine: true         
  network_effects: none       
  memory_bound: true          
  cpu_bound: true             
  memory_effects: low         

tags:
  - cpu
  - memory
  - json
  - parsing
  - requests
  - concurrency

dependencies:
  python: ">=3.8"
  requests: ">=2.28"

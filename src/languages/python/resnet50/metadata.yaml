# metadata.yaml for ResNet50 CPU benchmark
name: resnet50_cpu
type: macrobenchmark
language: Python
domain:
  - deep_learning
  - computer_vision
  - neural_networks

setup:
  command: python3 setup.py

workloads:
  - name: resnet50_inference
    summary: ResNet50 deep learning inference benchmark on CPU
    action: execute forward pass inference with ResNet50
    description: >
      Load pre-generated input data batches and execute the ResNet50 model in evaluation mode on the CPU.
      Perform forward pass computations to classify input images without updating model weights.
      Measure the latency and throughput of the inference process to evaluate CPU performance for deep learning workloads.
    data:
      command: python3 generate_data.py
      parameters:
        batch_size:
          description: Number of images per batch
          default: 4
        img_size:
          description: Size of each image
          default: 512
        num_batches:
          description: Number of batches to generate
          default: 10
        output_dir:
          description: Directory to save generated data
          default: "./data"
    command: python3 resnet_eval.py
    parameters:
      data_dir:
        description: Directory containing pre-generated input data batches
        default: "./data"
      threads:
        description: Number of CPU threads to use for inference
        default: 1
      iters:
        description: Number of benchmark iterations
        default: 50
      compile:
        description: Whether to use TorchDynamo compilation for inference
        default: false

  - name: resnet50_training
    summary: ResNet50 deep learning training benchmark on CPU
    action: perform model training with forward and backward passes
    description: >
      Load pre-generated training data and execute the ResNet50 model in training mode on the CPU.
      Compute the forward pass to generate predictions and calculate the loss, followed by the backward pass to compute gradients.
      Update model parameters using the SGD optimizer to evaluate the CPU's capability in handling full deep learning training cycles.
    data:
      command: python3 generate_data.py
      parameters:
        batch_size:
          description: Number of images per batch
          default: 4
        img_size:
          description: Size of each image
          default: 512
        num_batches:
          description: Number of batches to generate
          default: 10
        output_dir:
          description: Directory to save generated data
          default: "./data"
    command: python3 resnet_train.py
    parameters:
      data_dir:
        description: Directory containing pre-generated training data batches
        default: "./data"
      threads:
        description: Number of CPU threads to use for training
        default: 1
      lr:
        description: Learning rate for SGD optimizer
        default: 0.001
      iters:
        description: Number of benchmark iterations 
        default: 20
      compile:
        description: Whether to use TorchDynamo compilation for training
        default: false

characteristics:
  IO_effects: low
  single_machine: true
  network_effects: none
  cpu_bound: true
  memory_intensive: medium

tags:
  - deep_learning
  - computer_vision
  - neural_networks

dependencies:
  python: ">=3.8"
  torch: ">=2.0"
  torchvision: ">=0.15"
